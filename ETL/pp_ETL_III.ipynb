{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIR PROGRAMMING ETL III\n",
    "\n",
    "### ETL Transformación II - Clases y Funciones de limpieza\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lección de hoy aprendimos como Crearnos una clase que nos permita limpiar los datos obtenidos de la API.\n",
    "\n",
    "En este ejercicio, tendréis que crear una clase con el código que usamos en los ejercicios de pair programming de ETL Transformación I y II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ataquesclima:\n",
    "\n",
    "    def __init__(self, dicc_datos):\n",
    "\n",
    "        self.dicc_datos= dicc_datos\n",
    "\n",
    "    def conexion_API(self, producto):\n",
    "        \n",
    "        # Especificamos el producto del que queremos extraer la información\n",
    "        self.producto= producto\n",
    "       \n",
    "        # Creamos un dataframe vacío con las columnas que rellenaremos con la información obtenida de la API\n",
    "        df_clima_paises = pd.DataFrame( columns= ['timepoint', 'cloudcover', 'lifted_index', 'prec_type', 'prec_amount','temp2m', 'rh2m', 'weather', 'wind10m.direction', 'wind10m.speed','country'])\n",
    "\n",
    "        for key, value in self.dicc_datos.items(): \n",
    "\n",
    "            url =f'http://www.7timer.info/bin/api.pl?lon=-{self.dicc_datos[key][0]}&lat={self.dicc_datos[key][1]}&product={self.producto}&output=json'\n",
    "\n",
    "            response = requests.get(url=url)\n",
    "            response.status_code\n",
    "            response.reason\n",
    "            if codigo_estado == 200:\n",
    "                print('La peticion se ha realizado correctamente, se ha devuelto el código de estado:',codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            elif codigo_estado == 402:\n",
    "                print('No se ha podido autorizar usario, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            elif codigo_estado == 404:\n",
    "                print('Algo ha salido mal, el recurso no se ha encontrado,se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            else:\n",
    "                print('Algo inesperado ha ocurrido, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "\n",
    "            # Convetimos la información obtenida en formato json a un dataframe\n",
    "            df = pd.json_normalize(response.json()['dataseries']) \n",
    "            # Creamos una nueva columna para que inserte la key que corresponde al nombre del país\n",
    "            df['country']=key\n",
    "            # Concatenamos los dataframes de cada país en uno\n",
    "            df_clima_paises=pd.concat([df_clima_paises,df], axis=0, ignore_index = True)\n",
    "            return df_clima_paises\n",
    "\n",
    "\n",
    "    def limpiar_meteo(self, df_clima_paises): #(((((pendiente de cambiar a df, ya que puede ir cualquier df))))\n",
    "\n",
    "        df_clima_paises['rh_profile']= df_clima_paises['rh_profile'].apply(ast.literal_eval)\n",
    "        # Para separar la lista de diccionarios en varias columnas\n",
    "        x = df_clima_paises['rh_profile'].apply(pd.Series)     \n",
    "\n",
    "        # For loop para sacar el nombre de la columna y los valores de las filas\n",
    "        for i in range(len(x.columns)): \n",
    "    \n",
    "            # aplicamos el apply,extraemos el valor de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "            nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "            # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "            valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "            # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "            df_clima_paises.insert(i, nombre, valores)\n",
    "\n",
    "            \n",
    "\n",
    "        df_clima_paises['wind_profile']= df_clima_paises['wind_profile'].apply(ast.literal_eval)\n",
    "        y = df_clima_paises['wind_profile'].apply(pd.Series)\n",
    "\n",
    "        # For loop para sacar el nombre de la columna y los valores de las filas\n",
    "        for i in range(len(y.columns)): \n",
    "            \n",
    "            # aplicamos el apply,extraemos los valores de la key \"layer\" y lo almacenamos en dos variables que convertimos a strings\n",
    "            nombre = \"direction\" + str(y[i].apply(pd.Series)[\"layer\"][0]) \n",
    "            nombre2 = \"speed\" + str(y[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "            # hacemos lo mismo con dos variables para \"guardar\" los valores\n",
    "            valores = list(y[i].apply(pd.Series)[\"direction\"] )\n",
    "            valores2= list(y[i].apply(pd.Series)[\"speed\"] )\n",
    "\n",
    "            # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "            df_clima_paises.insert(i, nombre, valores)\n",
    "            df_clima_paises.insert(i,nombre2,valores2)\n",
    "\n",
    "\n",
    "\n",
    "            # Eliminamos las columnas que tienen las listas de diccionarios, información duplicada\n",
    "            df_clima_paises.drop(['rh_profile','wind_profile'], axis=1, inplace=True)\n",
    "\n",
    "            #Calculamos la media por pais\n",
    "            df_clima_paises = df_clima_paises.groupby('country').mean()\n",
    "\n",
    "            #Calculamos la fecha del dato y añadimos la columna al dataframe\n",
    "            hoy = datetime.now()\n",
    "            hoy = datetime.strftime(hoy, '%Y-%m-%d')\n",
    "            df_clima_paises[\"fecha\"] = hoy\n",
    "\n",
    "            #reseteamos el indice para guardar correctamente el df.\n",
    "            df_clima_paises.reset_index(inplace=True)\n",
    "\n",
    "            return df_clima_paises\n",
    "\n",
    "    def juntar_dfs(self, df_attacks, df_clima_paises): \n",
    "\n",
    "        df_union= df_attacks.merge(df_clima_paises, how= 'inner', on= 'country')\n",
    "\n",
    "\n",
    "        print(\"El df de union es \", df_union.columns)\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "                \n",
    "        # guardamos los datos\n",
    "        df_union.to_pickle('../files/datos_actualizados.pkl')\n",
    "        df_union.to_csv('../files/datos_actualizados.csv')\n",
    "\n",
    "        return df_union\n",
    "\n",
    "    def chequear_datos(self, df_union): \n",
    "    \n",
    "        print(\"Las columnas son:\", \"\\n\")\n",
    "        print(list(df_union.columns))\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "        print(\"Los tipos de datos que tenemos son:\", \"\\n\")\n",
    "        print(df_union.dtypes)\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "        print(\"El porcentaje de nulos:\", \"\\n\")\n",
    "        print((df_union.isnull().sum() / df_union.shape[0]) *  100)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Hacemos un diccionario con los países como keys y las coordenadas como values\n",
    "dicc_datos= {'usa': [-100.445882, 39.7837304],'australia': [134.755, -24.7761086],'south africa': [24.991639, -28.8166236],'new zealand': [172.8344077, -41.5000831],'papua new guinea': [144.2489081, -5.6816069]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = Ataquesclima(dicc_datos) # Iniciamos la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codigo_estado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/db/hp0l5_js4yv8br5y2tc3frpm0000gn/T/ipykernel_55282/379159723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconexion_API\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meteo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/db/hp0l5_js4yv8br5y2tc3frpm0000gn/T/ipykernel_55282/591596675.py\u001b[0m in \u001b[0;36mconexion_API\u001b[0;34m(self, producto)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcodigo_estado\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'La peticion se ha realizado correctamente, se ha devuelto el código de estado:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcodigo_estado\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' y como razón del código de estado: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrazon_estado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcodigo_estado\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m402\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'codigo_estado' is not defined"
     ]
    }
   ],
   "source": [
    "df= api.conexion_API('meteo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a52af493819045717511545598ab2b73dabca4ca61b402315e0ef2b43666342d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
