{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIR PROGRAMMING ETL III\n",
    "\n",
    "### ETL Transformación II - Clases y Funciones de limpieza\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lección de hoy aprendimos como Crearnos una clase que nos permita limpiar los datos obtenidos de la API.\n",
    "\n",
    "En este ejercicio, tendréis que crear una clase con el código que usamos en los ejercicios de pair programming de ETL Transformación I y II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ataquesclima:\n",
    "\n",
    "    def __init__(self, dicc_datos):\n",
    "\n",
    "        self.dicc_datos= dicc_datos\n",
    "\n",
    "    def conexion_API(self, producto):\n",
    "        \n",
    "        # Especificamos el producto del que queremos extraer la información\n",
    "        self.producto= producto\n",
    "       \n",
    "        # Creamos un dataframe vacío con las columnas que rellenaremos con la información obtenida de la API\n",
    "        df_clima_paises = pd.DataFrame( columns= ['timepoint', 'cloudcover', 'lifted_index', 'prec_type', 'prec_amount','temp2m', 'rh2m', 'weather', 'wind10m.direction', 'wind10m.speed','country'])\n",
    "\n",
    "        for key, value in self.dicc_datos.items(): \n",
    "\n",
    "            url =f'http://www.7timer.info/bin/api.pl?lon=-{self.dicc_datos[key][0]}&lat={self.dicc_datos[key][1]}&product={self.producto}&output=json'\n",
    "\n",
    "            response = requests.get(url=url)\n",
    "            codigo_estado = response.status_code\n",
    "            razon_estado = response.reason\n",
    "            if codigo_estado == 200:\n",
    "                print('La peticion se ha realizado correctamente, se ha devuelto el código de estado:',codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            elif codigo_estado == 402:\n",
    "                print('No se ha podido autorizar usario, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            elif codigo_estado == 404:\n",
    "                print('Algo ha salido mal, el recurso no se ha encontrado,se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "            else:\n",
    "                print('Algo inesperado ha ocurrido, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "\n",
    "            # Convetimos la información obtenida en formato json a un dataframe\n",
    "            df = pd.json_normalize(response.json()['dataseries']) \n",
    "            # Creamos una nueva columna para que inserte la key que corresponde al nombre del país\n",
    "            df['country']=key.lower()\n",
    "            # Concatenamos los dataframes de cada país en uno\n",
    "            df_clima_paises=pd.concat([df_clima_paises,df], axis=0, ignore_index = True)\n",
    "            return df_clima_paises\n",
    "\n",
    "\n",
    "    def limpiar_meteo(self, df_clima_paises): \n",
    "\n",
    "        self.df_clima_paises = df_clima_paises\n",
    "        \n",
    "        #df_clima_paises['rh_profile']= df_clima_paises['rh_profile'].apply(ast.literal_eval)\n",
    "        # Para separar la lista de diccionarios en varias columnas\n",
    "        x = df_clima_paises['rh_profile'].apply(pd.Series)     \n",
    "\n",
    "        # For loop para sacar el nombre de la columna y los valores de las filas\n",
    "        for i in range(len(x.columns)): \n",
    "        \n",
    "            # aplicamos el apply,extraemos el valor de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "            nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "            # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "            valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "            # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "            df_clima_paises.insert(i, nombre, valores)\n",
    "      \n",
    "            \n",
    "        #['wind_profile']= df_clima_paises['wind_profile'].apply(ast.literal_eval)\n",
    "        y = df_clima_paises['wind_profile'].apply(pd.Series)\n",
    "\n",
    "            # For loop para sacar el nombre de la columna y los valores de las filas\n",
    "        for i in range(len(y.columns)): \n",
    "                \n",
    "            # aplicamos el apply,extraemos los valores de la key \"layer\" y lo almacenamos en dos variables que convertimos a strings\n",
    "            nombre = \"direction\" + str(y[i].apply(pd.Series)[\"layer\"][0]) \n",
    "            nombre2 = \"speed\" + str(y[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "            # hacemos lo mismo con dos variables para \"guardar\" los valores\n",
    "            valores = list(y[i].apply(pd.Series)[\"direction\"] )\n",
    "            valores2= list(y[i].apply(pd.Series)[\"speed\"] )\n",
    "\n",
    "            # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "            df_clima_paises.insert(i, nombre, valores)\n",
    "            df_clima_paises.insert(i,nombre2,valores2)\n",
    "    \n",
    "\n",
    "            # Eliminamos las columnas que tienen las listas de diccionarios, información duplicada\n",
    "            df_clima_paises.drop(['rh_profile','wind_profile'], axis=1, inplace=True)\n",
    "\n",
    "            #Calculamos la media por pais\n",
    "            df_clima_paises = df_clima_paises.groupby('country').mean()\n",
    "\n",
    "            #Calculamos la fecha del dato y añadimos la columna al dataframe\n",
    "            hoy = datetime.now()\n",
    "            hoy = datetime.strftime(hoy, '%Y-%m-%d')\n",
    "            df_clima_paises[\"fecha\"] = hoy\n",
    "\n",
    "            #reseteamos el indice para guardar correctamente el df.\n",
    "            df_clima_paises.reset_index(inplace=True)\n",
    "            \n",
    "            print(f'Ya está listo el dataframes de meteo para juntarlo con el de ataques')\n",
    "            return df_clima_paises\n",
    "            \n",
    "\n",
    "    def juntar_dfs(self, df_attacks, df_clima_paises): \n",
    "        \n",
    "        self.df_attacks = df_attacks\n",
    "        self.df_clima_paises = df_clima_paises\n",
    "\n",
    "        df_union= df_attacks.merge(df_clima_paises, how= 'inner', on= 'country')\n",
    "\n",
    "\n",
    "        print(\"El df de union tiene las siguientes columnas: \\n\", list(df_union.columns))\n",
    "      \n",
    "        # guardamos los datos\n",
    "        df_union.to_pickle('../files/datos_actualizados.pkl')\n",
    "        df_union.to_csv('../files/datos_actualizados.csv')\n",
    "\n",
    "        return df_union\n",
    "\n",
    "    def chequear_datos(self, df_union): \n",
    "\n",
    "        print(f\"El número de filas son: {df_union.shape[0]}\\ny el número de columnas son: {df_union.shape[1]}\")\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "        print(\"Los tipos de datos que tenemos son:\", \"\\n\")\n",
    "        print(df_union.dtypes)\n",
    "        print(\"-----------------------------------------\")\n",
    "\n",
    "        print(\"El porcentaje de nulos:\", \"\\n\")\n",
    "        print((df_union.isnull().sum() / df_union.shape[0]) *  100)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Hacemos un diccionario con los países como keys y las coordenadas como values\n",
    "dicc_datos= {'usa': [-100.445882, 39.7837304],'australia': [134.755, -24.7761086],'south africa': [24.991639, -28.8166236],'new zealand': [172.8344077, -41.5000831],'papua new guinea': [144.2489081, -5.6816069]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = Ataquesclima(dicc_datos) # Iniciamos la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La peticion se ha realizado correctamente, se ha devuelto el código de estado: 200  y como razón del código de estado:  OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timepoint</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>lifted_index</th>\n",
       "      <th>prec_type</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>temp2m</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind10m.direction</th>\n",
       "      <th>wind10m.speed</th>\n",
       "      <th>country</th>\n",
       "      <th>highcloud</th>\n",
       "      <th>midcloud</th>\n",
       "      <th>lowcloud</th>\n",
       "      <th>rh_profile</th>\n",
       "      <th>wind_profile</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 5}, {'layer': '900mb...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 150, 'speed':...</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 6}, {'layer': '900mb...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 265, 'speed':...</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timepoint cloudcover lifted_index prec_type prec_amount temp2m rh2m weather  \\\n",
       "0         3          7            6      none           0     16    4     NaN   \n",
       "1         6          8            6      none           0     15    6     NaN   \n",
       "\n",
       "  wind10m.direction wind10m.speed country  highcloud  midcloud  lowcloud  \\\n",
       "0               110             2     usa    -9999.0   -9999.0   -9999.0   \n",
       "1               220             2     usa    -9999.0   -9999.0   -9999.0   \n",
       "\n",
       "                                          rh_profile  \\\n",
       "0  [{'layer': '950mb', 'rh': 5}, {'layer': '900mb...   \n",
       "1  [{'layer': '950mb', 'rh': 6}, {'layer': '900mb...   \n",
       "\n",
       "                                        wind_profile  msl_pressure  snow_depth  \n",
       "0  [{'layer': '950mb', 'direction': 150, 'speed':...        1024.0         0.0  \n",
       "1  [{'layer': '950mb', 'direction': 265, 'speed':...        1025.0         0.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clima_paises= api.conexion_API('meteo') # Hacemos la llamada a la API\n",
    "df_clima_paises.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya está listo el dataframes de meteo para juntarlo con el de ataques\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2489/1731046026.py:83: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_clima_paises = df_clima_paises.groupby('country').mean()\n"
     ]
    }
   ],
   "source": [
    "df_clima_paises = api.limpiar_meteo(df_clima_paises)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>speed950mb</th>\n",
       "      <th>direction950mb</th>\n",
       "      <th>rh_950mb</th>\n",
       "      <th>rh_900mb</th>\n",
       "      <th>rh_850mb</th>\n",
       "      <th>rh_800mb</th>\n",
       "      <th>rh_750mb</th>\n",
       "      <th>rh_700mb</th>\n",
       "      <th>rh_650mb</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_350mb</th>\n",
       "      <th>rh_300mb</th>\n",
       "      <th>rh_250mb</th>\n",
       "      <th>rh_200mb</th>\n",
       "      <th>highcloud</th>\n",
       "      <th>midcloud</th>\n",
       "      <th>lowcloud</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usa</td>\n",
       "      <td>2.875</td>\n",
       "      <td>234.6875</td>\n",
       "      <td>4.375</td>\n",
       "      <td>5.140625</td>\n",
       "      <td>5.65625</td>\n",
       "      <td>4.71875</td>\n",
       "      <td>3.1875</td>\n",
       "      <td>2.59375</td>\n",
       "      <td>2.296875</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3125</td>\n",
       "      <td>6.140625</td>\n",
       "      <td>7.296875</td>\n",
       "      <td>5.984375</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1019.5625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  speed950mb  direction950mb  rh_950mb  rh_900mb  rh_850mb  rh_800mb  \\\n",
       "0     usa       2.875        234.6875     4.375  5.140625   5.65625   4.71875   \n",
       "\n",
       "   rh_750mb  rh_700mb  rh_650mb  ...  rh_350mb  rh_300mb  rh_250mb  rh_200mb  \\\n",
       "0    3.1875   2.59375  2.296875  ...    5.3125  6.140625  7.296875  5.984375   \n",
       "\n",
       "   highcloud  midcloud  lowcloud  msl_pressure  snow_depth       fecha  \n",
       "0    -9999.0   -9999.0   -9999.0     1019.5625         0.0  2023-01-11  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clima_paises.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks = pd.read_pickle(\"../files/attacks12.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El df de union tiene las siguientes columnas: \n",
      " ['case_number', 'type', 'country', 'activity', 'age', 'species_', 'date', 'mes_ataque', 'fatal', 'sexo', 'cat_species', 'mes', 'year', 'edades', 'speed950mb', 'direction950mb', 'rh_950mb', 'rh_900mb', 'rh_850mb', 'rh_800mb', 'rh_750mb', 'rh_700mb', 'rh_650mb', 'rh_600mb', 'rh_550mb', 'rh_500mb', 'rh_450mb', 'rh_400mb', 'rh_350mb', 'rh_300mb', 'rh_250mb', 'rh_200mb', 'highcloud', 'midcloud', 'lowcloud', 'msl_pressure', 'snow_depth', 'fecha']\n"
     ]
    }
   ],
   "source": [
    "df_union= api.juntar_dfs(df_attacks, df_clima_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas son: 741\n",
      "y el número de columnas son: 38\n",
      "-----------------------------------------\n",
      "Los tipos de datos que tenemos son: \n",
      "\n",
      "case_number        object\n",
      "type               object\n",
      "country            object\n",
      "activity           object\n",
      "age                object\n",
      "species_           object\n",
      "date               object\n",
      "mes_ataque         object\n",
      "fatal              object\n",
      "sexo               object\n",
      "cat_species        object\n",
      "mes                object\n",
      "year              float64\n",
      "edades            float64\n",
      "speed950mb        float64\n",
      "direction950mb    float64\n",
      "rh_950mb          float64\n",
      "rh_900mb          float64\n",
      "rh_850mb          float64\n",
      "rh_800mb          float64\n",
      "rh_750mb          float64\n",
      "rh_700mb          float64\n",
      "rh_650mb          float64\n",
      "rh_600mb          float64\n",
      "rh_550mb          float64\n",
      "rh_500mb          float64\n",
      "rh_450mb          float64\n",
      "rh_400mb          float64\n",
      "rh_350mb          float64\n",
      "rh_300mb          float64\n",
      "rh_250mb          float64\n",
      "rh_200mb          float64\n",
      "highcloud         float64\n",
      "midcloud          float64\n",
      "lowcloud          float64\n",
      "msl_pressure      float64\n",
      "snow_depth        float64\n",
      "fecha              object\n",
      "dtype: object\n",
      "-----------------------------------------\n",
      "El porcentaje de nulos: \n",
      "\n",
      "case_number       0.000000\n",
      "type              0.000000\n",
      "country           0.000000\n",
      "activity          0.269906\n",
      "age               2.564103\n",
      "species_          2.024291\n",
      "date              0.000000\n",
      "mes_ataque        2.699055\n",
      "fatal             6.207827\n",
      "sexo              0.000000\n",
      "cat_species       2.024291\n",
      "mes               3.508772\n",
      "year              0.000000\n",
      "edades            0.000000\n",
      "speed950mb        0.000000\n",
      "direction950mb    0.000000\n",
      "rh_950mb          0.000000\n",
      "rh_900mb          0.000000\n",
      "rh_850mb          0.000000\n",
      "rh_800mb          0.000000\n",
      "rh_750mb          0.000000\n",
      "rh_700mb          0.000000\n",
      "rh_650mb          0.000000\n",
      "rh_600mb          0.000000\n",
      "rh_550mb          0.000000\n",
      "rh_500mb          0.000000\n",
      "rh_450mb          0.000000\n",
      "rh_400mb          0.000000\n",
      "rh_350mb          0.000000\n",
      "rh_300mb          0.000000\n",
      "rh_250mb          0.000000\n",
      "rh_200mb          0.000000\n",
      "highcloud         0.000000\n",
      "midcloud          0.000000\n",
      "lowcloud          0.000000\n",
      "msl_pressure      0.000000\n",
      "snow_depth        0.000000\n",
      "fecha             0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "api.chequear_datos(df_union)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819a5c43c1fad9e35c5b1180124e231b422fc24c453463d400a90e0aae1b9c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
